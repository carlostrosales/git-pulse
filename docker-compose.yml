#
# Docker Compose Stack for Local Development
# ------------------------------------------
# This stack sets up a local development environment with the following services:
#
# 1. Kafka (KRaft mode - no ZooKeeper):
#    - Uses Confluent Platform Kafka 7.4.0 with KRaft (Kafka Raft Metadata mode).
#    - Runs as both a broker and a controller.
#    - Ports:
#        - 9092: External client connections (PLAINTEXT)
#        - 9093: Internal controller communication
#    - Uses a named volume `kraft_data` for persistent storage of Kafka logs and metadata.
#
# 2. PostgreSQL:
#    - Version 15 of PostgreSQL for relational database needs.
#    - Accessible on port 5432.
#    - Initializes with:
#        - user: dev
#        - password: devpass
#        - database: devdb
#    - Persists data in `postgres_data` volume.
#
# 3. Redis:
#    - In-memory data store (version 7).
#    - Useful for caching, queueing, or pub/sub patterns.
#    - Exposed on port 6379.
#
# 4. MinIO (S3-compatible object storage):
#    - Lightweight, self-hosted alternative to AWS S3.
#    - Console accessible at port 9001; S3 API available on port 9000.
#    - Root credentials set to `minioadmin` / `minioadmin`.
#    - Stores data in `minio_data` volume.
#
# 5. Python Script:
#    - Script to download, read, and write binary data into Kafka Topic
#
#
# Volumes:
#   - postgres_data: persists PostgreSQL data
#   - minio_data: persists MinIO object store
#   - kraft_data: persists Kafka broker and controller logs (in KRaft mode)
#
# Notes:
#   - This is a good base stack for projects needing event streaming (Kafka), relational DB persistence (PostgreSQL),
#     caching (Redis), and object storage (MinIO).
#   - All services run on default ports and can be accessed from the host machine.
#   - You can expand this setup by adding Kafka clients, a Kafka UI, or schema registry.
#

services:
  kafka:
    image: confluentinc/cp-kafka:7.4.0
    container_name: kafka
    ports:
      - "9092:9092"
      - "9093:9093"
    environment:
      CLUSTER_ID: "N-1JTbT7TcmqFz1IlIUqyw"  # required for KRaft mode init
      KAFKA_NODE_ID: 1
      # Below is what roles this Kafka node will serve in KRaft mode. Defines the node's roles.
      # In KRaft mode, there is no Zookeeper.
      # Each node can act as:
        # 'broker': servers client traffic (produce/consume)
        # 'controller': manages metadata, topic configs, partitions
      # Can assign both roles to one node in development
      KAFKA_PROCESS_ROLES: broker,controller
      # Below defines the controller quorum (like ZK ensemble, but in KRaft)
      # Says this cluster ahs 1 controller, reachable at host 'kafka', port '9093'
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka:9093"
      # Below is where Kafka listens for connections - internal network bindings. Actual network bindings (internal). What address the Kafka server/broker binds to.
      # This is the interface and port that the Kafka broker binds to and listens for connections.
      # This configures Kafka to listen for connections:
        # PLAINTEXT://kafka:9092 -> for client connections (producers/consumers)
        # CONTROLLER://kafka:9093 -> for KRaft controller communication
      # 'kafka' here is the container hostname (Docker service name). So inside the Docker network, other services can reach this broker at 'kafka:9092'
      KAFKA_LISTENERS: PLAINTEXT://kafka:9092,CONTROLLER://kafka:9093
      # Below is how Kafka tells other to reach it - the public-facing address. This is how clients connect. What address it tells clients to dial (producers, consumers, CLI)
      # This is the address Kafka gives back to clients (producers/consumers)
      # If set to 'localhost:9092', that only works outside the container, not from inside it.
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      # Below tells which listener name is used for controller communication. Specifies which listeners handles controller-to-controller traffic.
      # Tells Kafka: "use the lsitener named 'CONTROLLER' for controller communication"
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT
      KAFKA_LOG_DIRS: /var/lib/kafka/data
    entrypoint: >
      bash -c "
      if [ ! -f /var/lib/kafka/data/meta.properties ]; then
        echo 'ðŸŒ€ Initializing Kafka with KRaft cluster ID...'
        kafka-storage format --cluster-id=$${CLUSTER_ID} --config /etc/kafka/kafka.properties
      fi;
      exec /etc/confluent/docker/run
      "
    volumes:
      - kraft_data:/var/lib/kafka/data

  postgres:
    image: postgres:15  # PostgreSQL 15 database
    container_name: postgres
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: dev  # Username for the DB
      POSTGRES_PASSWORD: devpass  # Password for the DB
      POSTGRES_DB: devdb  # Default database name
    volumes:
      - postgres_data:/var/lib/postgresql/data  # Persist PostgreSQL data

  redis:
    image: redis:7  # Redis in-memory data store
    container_name: redis
    ports:
      - "6379:6379"  # Default Redis port

  minio:
    image: minio/minio:latest  # MinIO object storage (S3 compatible)
    container_name: minio
    ports:
      - "9000:9000"  # MinIO S3 endpoint
      - "9001:9001"  # MinIO Web UI
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin
    command: server /data --console-address ":9001"
    volumes:
      - minio_data:/data  # Persist uploaded objects

  data-ingestion:
    build: ./data-ingestion
    depends_on:
      - kafka

  kafdrop:
    image: obsidiandynamics/kafdrop
    container_name: kafdrop
    ports:
      - "9002:9000"  # Expose web UI at localhost:9002
    environment:
      KAFKA_BROKERCONNECT: kafka:9092
      JVM_OPTS: "-Xms32M -Xmx64M"
    depends_on:
      - kafka


volumes:
  postgres_data:
  minio_data:
  kraft_data:
